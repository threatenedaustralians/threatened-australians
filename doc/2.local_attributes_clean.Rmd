---
title: Cleaning the non-spatial attributes of the data
author: Gareth Kindler
output:
    html_document:
        code_folding: show
---

This document details the cleaning of the non-spatial attributes data relevant to the Threatened Australians (threatened.org.au) project. It is the second of four documents.

## Libraries

```{r, eval = FALSE, class.source = 'fold-hide'}
library(tidyverse)
library(sf)
library(magrittr)
library(jsonlite)
library(units)
library(readxl)
library(stringr)
library(rmapshaper)
library(httpgd)
```

## Import: Electoral

### Data key
`postcodes`:
Postal Areas (POAs) were retreived from the Australian Bureau of Statistics (ABS) [Australian Statistical Geography Standard (ASGS) Edition 3](https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/non-abs-structures/postal-areas).

`demo`:
Demographic classification of Commonwealth Electoral Divisions (CEDs) was retrieved from the [Australian Electoral Commission (AEC)](https://www.aec.gov.au/Electorates/maps.htm).

`MP_info`:
Information about each Minister of Parliament (MP). Pulled from the Australian Parliament House API. Script for this can be found `~/scripts/MP_info/req_MP_info.py`

`MP_voting_info`:
Information about each MPs voting track record. Pulled from [They Vote For You](https://theyvoteforyou.org.au/) API. Script can be found at `~/scripts/MP_voting_info/req_MP_voting_info.py`

```{r, eval = FALSE, setup}
knitr::opts_knit$set(root.dir = "/tmp")
elects <- st_read(
    "output/clean_data/elects_clean.gpkg"
)
postcodes <- st_read(
    "data/POA_2021_AUST_GDA94_SHP/POA_2021_AUST_GDA94.shp"
)
demo <- readxl::read_xlsx(
    "data/AEC_demographic-classification-1-january-2019/01-demographic-classification-as-at-1-january-2019.xlsx"
)
MP_info <- fromJSON(
    "data/MP_info.json"
)
MP_voting_info <- fromJSON(
    "data/MP_voting_info.json"
)
```

## Import: Threatened Species

### Data key
`animals_images`:
Gathering image URLs was a messy task. The steps for this were: \
1. Query the Atlas of Living Australia (ALA) API and take the first image URL - this was done using `~/scripts/images/req_ALA_image_URLs.py` \
2. Create a spreadsheet to check those ALA URLs and manually scourer the web for URLs of other images (gruelling work - 372 animal species and the ALA didn't return the majority) \
3. Import this spreadsheet into this script \

`animals_info`:
Information on threatened species was done by scraping the Species Profile and Threats (SPRAT) Database for description and habitat information using the script found at `~/scripts/species_info/scrape_SPRAT.py`. This was also quite messy and involved manual oversight/intervention which we'll describe later in this doc.

`threats`:
For the most up-to-date information on threats facing Australian imperilled species:

>  Ward, M., Carwardine, J., Yong, C. J., Watson, J. E. M., Silcock, J., Taylor, G. S., Lintermans, M., Gillespie, G. R., Garnett, S. T., Woinarski, J., Tingley, R., Fensham, R. J., Hoskin, C. J., Hines, H. B., Roberts, J. D., Kennard, M. J., Harvey, M. S., Chapple, D. G., & Reside, A. E. (2021). A national-scale dataset for threats impacting Australia’s imperiled flora and fauna. Ecology and Evolution, 11, 11749– 11761. https://doi.org/10.1002/ece3.7920

`animals_ft`:
This is a dataframe used to filter (`ft`) others based on the final species we'll be including on the web app. Check `4.local_compiling.Rmd` for its script of how it was calculated.

```{r, eval = FALSE}
species <- st_read(
    "output/clean_data/species_clean.gpkg"
)
animals_images <- read_csv(
    "data/animals_image_vetting/animals_image_vetting - ft_combined.csv"
)
animals_info <- fromJSON(
    "data/animals_info_vetting/animals_info_SPRAT.json"
)
threats <- readxl::read_excel(
    "data/Ward_2019_national_dataset_imperiled_appendix_S1.xlsx",
    "Species-Threat-Impact"
)
animals_ft <- fromJSON(
    "output/clean_data/animals_ft.json"
)
```

## Clean: Electoral

### Postcodes

```{r, eval = FALSE}
postcodes_clean <- postcodes %>%
    select(
        POA_CODE21, AREASQKM21, geometry
    ) %>%
    filter(
        !POA_CODE21 %in% c("9494", "9797", "ZZZZ")
    ) %>%
    rename(
        POA_code = POA_CODE21,
        POA_area_sqkm = AREASQKM21
    ) %T>%
    st_write(
        "output/clean_data/postcodes_clean.gpkg",
        layer = "postcodes_clean", append = FALSE, delete_dsn = TRUE
    )
```

### MP information

Mr Nick Champion MP was "elected to the House of Representatives for Spence, South Australia following electoral redistribution, 2019. Resigned 22.2.2022.". As the APH API did not include Nick Champion as a member anymore, we added him back in.

```{r, eval = FALSE}
MP_info_clean <- MP_info %>%
    mutate(
        electorate = word(
            .$representing, 1,
            sep = ","
        )
    ) %>%
    distinct() %>%
    relocate(
        electorate,
        .after = representing
    ) %>%
    add_row(
        MP_ID = "HW9",
        full_name = "Nicholas David Champion",
        titles = "NA",
        representing = "Spence, South Australia",
        electorate = "Spence", # can link to TVFY on electorate attribute
        email_address = "NA",
        Twitter_address = "NA",
        Facebook_address = "NA",
        image_URL = "https://www.aph.gov.au/api/parliamentarian/HW9/image",
        former_member = as.logical("TRUE"),
        date_elected = "2019-05-18T00:000:00"
    ) %T>%
    write_json(
        "output/clean_data/MP_info_clean.json"
    )
```

### MP voting information

The data we pulled from TVFY API's came with two former MPs and a senator. We removed them, and replaced the data with neccessary information.
These MPs and senators are:

> [Nick Champion 10111](https://www.aph.gov.au/Senators_and_Members/Parliamentarian?MPID=HW9) \
> [John McVeigh 10889](https://www.aph.gov.au/Senators_and_Members/Parliamentarian?MPID=125865) \
> [David Feeney 10709](https://www.aph.gov.au/Senators_and_Members/Parliamentarian?MPID=I0O) \

```{r, eval = FALSE}
MP_voting_info_clean <- MP_voting_info %>%
    filter(
        !ID %in% c(10111, 10889, 10709)
    ) %>%
    mutate(
        party = replace(
            party, party == "SPK", "Liberal Party"
        )
    ) %>%
    mutate(
        party = replace(
            party, party == "CWM", "National Party"
        )
    ) %>%
    add_row(
        ID = NA,
        first = "NA",
        last = "NA",
        house = "representatives",
        electorate = "Spence", # can link to TVFY on electorate attribute
        category = "NA",
        party = "Australian Labor Party",
        url = "NA"
    ) %T>%
    write_json(
        "output/clean_data/MP_voting_info_clean.json"
    )
```

### Demographic classification of the CEDs

We cleaned up the data to be consistent and added in some acronyms.

```{r, eval = FALSE}
demo_clean <- demo %>%
    rename(
        state_territory = "State or territory",
        demographic_class = "Demographic classification",
        electorate = "Electoral division"
    ) %>%
    mutate(
        state_territory = replace(
            state_territory, state_territory == "ACT", "Australian Capital Territory"
        )
    ) %>%
    mutate(
        state_territory = replace(
            state_territory, state_territory == "NT", "Northern Territory"
        )
    ) %>%
    mutate(
        state_territory_abbrev = case_when(
            state_territory == "Australian Capital Territory" ~ "ACT",
            state_territory == "New South Wales" ~ "NSW",
            state_territory == "Northern Territory" ~ "NT",
            state_territory == "Queensland" ~ "QLD",
            state_territory == "South Australia" ~ "SA",
            state_territory == "Tasmania" ~ "TAS",
            state_territory == "Victoria" ~ "VIC",
            state_territory == "Western Australia" ~ "WA"
        )
    ) %T>%
    write_json(
        "output/clean_data/demo_clean.json"
    )
```

## Clean (Bonus): Species

### Filter: Freshwater and terrestrial

The SNES data attributes of `marine` and `cetacean` don't capture all species of these categories so some manual cleaning needed to occur.

```{r, eval = FALSE}
species_FT_animals_clean <- species %>%
    st_set_geometry(NULL) %>%
    filter(
        taxon_kingdom %in% "Animalia"
    ) %>%
    filter(
        !marine %in% c(
            "Listed", "Listed - overfly marine area"
        )
    ) %>%
    filter(
        !cetacean %in% "Cetacean"
    ) %>%
    filter(
        !scientific_name %in% c(
            "Brachionichthys hirsutus", # Spotted Handfish
            "Brachiopsilus ziebelli", # Ziebell's Handfish, Waterfall Bay Handfish
            "Carcharias taurus (east coast population)", # Grey Nurse Shark (east coast population)
            "Carcharias taurus (west coast population)", # Grey Nurse Shark (west coast population)
            "Carcharodon carcharias", # White Shark, Great White Shark
            "Epinephelus daemelii", # Black Rockcod, Black Cod, Saddled Rockcod
            "Glyphis garricki", # Northern River Shark, New Guinea River Shark
            "Glyphis glyphis", # Speartooth Shark
            "Pristis clavata", # Dwarf Sawfish, Queensland Sawfish
            "Rhincodon typus", # Whale Shark
            "Thymichthys politus", # Red Handfish
            "Zearaja maugeana", # Maugean Skate, Port Davey Skate
            "Thunnus maccoyii" # Southern Bluefin Tuna
        )
    ) %T>%
    write_json(
        "output/clean_data/species_FT_animals_clean.json"
    )
```

### Filter: Plants

```{r, eval = FALSE}
species_plants_clean <- species %>%
    st_set_geometry(NULL) %>%
    filter(
        taxon_kingdom %in% "Plantae"
    ) %T>%
    # filter(
    #     !marine %in% c(
    #         "Listed", "Listed - overfly marine area"
    #     )
    # ) %T>%
    write_json(
        "output/clean_data/species_plants_clean.json"
    )
```

### Filter: Marine

```{r, eval = FALSE}
species_marine_clean <- species %>%
    st_set_geometry(NULL) %>%
    filter(
        marine %in% c(
            "Listed", "Listed - overfly marine area"
        ) |
            cetacean %in% "Cetacean" |
            scientific_name %in% c(
                "Brachionichthys hirsutus", # Spotted Handfish
                "Brachiopsilus ziebelli", # Ziebell's Handfish, Waterfall Bay Handfish
                "Carcharias taurus (east coast population)", # Grey Nurse Shark (east coast population)
                "Carcharias taurus (west coast population)", # Grey Nurse Shark (west coast population)
                "Carcharodon carcharias", # White Shark, Great White Shark
                "Epinephelus daemelii", # Black Rockcod, Black Cod, Saddled Rockcod
                "Glyphis garricki", # Northern River Shark, New Guinea River Shark
                "Glyphis glyphis", # Speartooth Shark
                "Pristis clavata", # Dwarf Sawfish, Queensland Sawfish
                "Rhincodon typus", # Whale Shark
                "Thymichthys politus", # Red Handfish
                "Zearaja maugeana", # Maugean Skate, Port Davey Skate
                "Thunnus maccoyii" # Southern Bluefin Tuna
            )
    ) %T>%
    write_json(
        "output/clean_data/species_marine_clean.json"
    )
```

## Clean: Threats

As the project has no target audience and wants to be accessible for all persons, we opted to focus on broad scale threats identified through the IUCN criteria used in the research article. And this has added benefits of simplicity to the project.

We then recoded the data with a `threat_ID` for linking attributes in our SQL database.

```{r, eval = FALSE}
names(threats) <- make.names(names(threats), unique = TRUE)

threats_clean <- threats %>%
    rename(
        species_name_adjusted = Species.name.adjusted,
        scientific_name = Species.name,
        vernacular_name = Common.name,
        broad_level_threat = Broad.level.threat,
        taxon_group = Group
    ) %>%
    select(
        species_name_adjusted, scientific_name,
        vernacular_name, broad_level_threat,
        taxon_group
    ) %>%
    group_by(
        species_name_adjusted, broad_level_threat
    ) %>%
    summarise() %>%
    ungroup() %>%
    rename(
        scientific_name = species_name_adjusted
    ) %>%
    inner_join(species) %>%
    select(
        taxon_ID, broad_level_threat
    ) %>%
    mutate(
        threat_ID =
            case_when(
                broad_level_threat == "Adverse fire regimes" ~ "T01",
                broad_level_threat == "Changed surface and groundwater regimes" ~ "T02",
                broad_level_threat == "Climate change and severe weather" ~ "T03",
                broad_level_threat == "Disrupted ecosystem and population processes" ~ "T04",
                broad_level_threat == "Habitat loss, fragmentation and degradation" ~ "T05",
                broad_level_threat == "Invasive species and diseases" ~ "T06",
                broad_level_threat == "Overexploitation and other direct harm from human activities" ~ "T07",
                broad_level_threat == "Pollution" ~ "T08"
            )
    ) %T>%
    write_json(
        "output/clean_data/threats_clean.json"
    )
```

```{r, eval = FALSE}
#### Collapse: threats ####

threats_collapsed_clean <- threats_clean %>%
    group_by(
        taxon_ID
    ) %>%
    summarise(
        threat_ID_collapsed = paste(threat_ID, collapse = ", ")
    ) %>%
    ungroup() %T>%
    write_json(
        "output/clean_data/threats_collapsed_clean.json"
    )
```

## Clean: Animals Info

To information scraped from SPRAT was messy and needed special characters to be removed along with replacements for null values. We decided to not include `habitat` information as this had added work and was deemed feature creep.

```{r, eval = FALSE}
animals_info_for_vetting <- animals_info %>%
    mutate(
        taxon_ID = as.character(taxon_ID)
    ) %>%
    inner_join(animals_ft) %>%
    # mutate(
    #     habitat = str_remove_all(
    #             habitat,
    #             "<.*?>"
    #         )
    #     ) %>%
    mutate(
        description = str_remove_all(
                description,
                "<.*?>"
            )
        ) %>%
    mutate(
        description = str_remove_all(
                description,
                " \\(.*?\\)"
            )
        ) %>%
    mutate(
        description = str_remove_all(
                description,
                "\\(.*?\\)"
            )
        ) %>%
    mutate(
        description = trimws(
                description
            )
        ) %>%
    mutate(
        description = str_replace(
                description,
                "NA",
                "No information was found for this species on the Species Profile and Threats Database (SPRAT) website, which is the database designed to provide information on species listed as threatened under the Environment Protection and Biodiversity Conservation (EPBC) Act 1999. This does not mean there is no information out there. We encourage you to do a web search using the scientific latin name."
            )
        ) %>%
    # mutate(
    #     description = trimws(
    #         str_remove_all(
    #             description,
    #             "[^a-zA-Z0-9 -,'.]"
    #         )
    #     )
    # ) %>%
    # mutate(
    #     habitat = trimws(
    #         str_remove_all(
    #             habitat,
    #             "[^a-zA-Z0-9 -,'.]"
    #         )
    #     )
    # ) %>%
    select(
        taxon_ID, scientific_name, vernacular_name,
        SPRAT_profile, description
    ) %T>%
    write_csv(
        "data/animals_info_vetting/animals_info_for_vetting.csv"
    )
```

It also needed further manual clenaing, which was done in GUI spreadsheets. We then re-imported the data.

```{r, eval = FALSE}
animals_info_vetted <- read_csv(
    "data/animals_info_vetting/animals_info_vettting - animals_info_vetted.csv"
)
animals_info_clean <- animals_info_vetted %>%
    select(taxon_ID, description) %T>%
    write_json(
        "output/clean_data/animals_info_clean.json"
    )
```

## Clean: Images

The manually created spreadsheet has two key attributes:
`ALA_API_image_URL`: the ALA image URLs. Sometimes these were images of roadkill or taxidermy, so even this involved manual oversight.
`alt_URL`: the alternative image URL to use

To get the best sized image from the ALA URLs, we removed the `Thumbnail` text.

```{r, eval = FALSE}
animals_images_clean <- animals_images %>%
    select(
        taxon_ID, ALA_URL,
        ALA_API_image_URL, alt_URL
        ) %>%
    mutate(
        image_URL =
            case_when(
                grepl("http", alt_URL) ~ paste0(alt_URL),
                grepl("http", ALA_API_image_URL) ~ paste0(ALA_API_image_URL),
                TRUE ~ "http://nickkellyresearch.com/wp-content/uploads/2022/03/Yellow-Footed-Rock-Wallaby.jpeg"
            )
        ) %>%
    mutate(
        image_URL =
            case_when(
                grepl(
                    "https://images.ala.org.au", image_URL
                ) ~ str_remove_all(
                    .$image_URL,
                    "ThumbnailLarge"
                ),
                TRUE ~ paste0(
                    image_URL
                )
            )
        ) %>%
    mutate(
        image_URL =
            case_when(
                grepl(
                    "https://images.ala.org.au", image_URL
                ) ~ str_remove_all(
                    .$image_URL,
                    "Thumbnail"
                ),
                TRUE ~ paste0(
                    image_URL
                )
            )
        ) %>%
    select(
        !c(
            alt_URL, ALA_API_image_URL,
        )
    ) %T>%
    write_json(
        "output/clean_data/animals_images_clean.json"
    )
```
